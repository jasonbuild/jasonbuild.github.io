[{"authors":["admin"],"categories":null,"content":"I am is a full-stack engineer. He has extensive experiences in scalable data collection, machine learning, and web applications prototypeing.\nThis is my personal website for knowledge shareing and idea demostration.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://jasonbuild.github.io/author/jason-ng/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jason-ng/","section":"authors","summary":"I am is a full-stack engineer. He has extensive experiences in scalable data collection, machine learning, and web applications prototypeing.\nThis is my personal website for knowledge shareing and idea demostration.","tags":null,"title":"Jason Ng","type":"authors"},{"authors":[],"categories":[],"content":"install hugo https://rimdev.io/hugo-extended-latest-install-script-for-macos/\npublish to github pages https://sourcethemes.com/academic/docs/deployment/#github-pages\nupdate git add . git commit -m \u0026quot;Initial commit\u0026quot; git push -u origin master  hugo cd public git add . git commit -m \u0026quot;Build website\u0026quot; git push origin master cd ..  ","date":1592149948,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592149948,"objectID":"1ba1da42e133e1a006844b4b012bf188","permalink":"https://jasonbuild.github.io/post/hugo/","publishdate":"2020-06-14T23:52:28+08:00","relpermalink":"/post/hugo/","section":"post","summary":"install hugo https://rimdev.io/hugo-extended-latest-install-script-for-macos/\npublish to github pages https://sourcethemes.com/academic/docs/deployment/#github-pages\nupdate git add . git commit -m \u0026quot;Initial commit\u0026quot; git push -u origin master  hugo cd public git add . git commit -m \u0026quot;Build website\u0026quot; git push origin master cd .","tags":[],"title":"Hugo","type":"post"},{"authors":[],"categories":[],"content":"multithread import urllib2 from multiprocessing.dummy import Pool as ThreadPool urls = [ 'http://www.python.org', 'http://www.python.org/about/', 'http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html', 'http://www.python.org/doc/', 'http://www.python.org/download/', 'http://www.python.org/getit/', 'http://www.python.org/community/', 'https://wiki.python.org/moin/', 'http://planet.python.org/', 'https://wiki.python.org/moin/LocalUserGroups', 'http://www.python.org/psf/', 'http://docs.python.org/devguide/', 'http://www.python.org/community/awards/' # etc.. ] # Make the Pool of workers pool = ThreadPool(4) # Open the urls in their own threads # and return the results results = pool.map(urllib2.urlopen, urls) #close the pool and wait for the work to finish pool.close() pool.join()  multiprocess from multiprocessing import Pool from PIL import Image SIZE = (75,75) SAVE_DIRECTORY = 'thumbs' def get_image_paths(folder): return (os.path.join(folder, f) for f in os.listdir(folder) if 'jpeg' in f) def create_thumbnail(filename): im = Image.open(filename) im.thumbnail(SIZE, Image.ANTIALIAS) base, fname = os.path.split(filename) save_path = os.path.join(base, SAVE_DIRECTORY, fname) im.save(save_path) if __name__ == '__main__': folder = os.path.abspath( '11_18_2013_R000_IQM_Big_Sur_Mon__e10d1958e7b766c3e840') os.mkdir(os.path.join(folder, SAVE_DIRECTORY)) images = get_image_paths(folder) pool = Pool() pool.map(create_thumbnail, images) pool.close() pool.join()  ","date":1592149581,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592149581,"objectID":"e4726e265f1958ffdb381fddf22e0283","permalink":"https://jasonbuild.github.io/post/python-parallel/","publishdate":"2020-06-14T23:46:21+08:00","relpermalink":"/post/python-parallel/","section":"post","summary":"multithread import urllib2 from multiprocessing.dummy import Pool as ThreadPool urls = [ 'http://www.python.org', 'http://www.python.org/about/', 'http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html', 'http://www.python.org/doc/', 'http://www.python.org/download/', 'http://www.python.org/getit/', 'http://www.python.org/community/', 'https://wiki.python.org/moin/', 'http://planet.python.org/', 'https://wiki.python.org/moin/LocalUserGroups', 'http://www.python.org/psf/', 'http://docs.python.org/devguide/', 'http://www.python.org/community/awards/' # etc.. ] # Make the Pool of workers pool = ThreadPool(4) # Open the urls in their own threads # and return the results results = pool.","tags":[],"title":"Python Parallel","type":"post"}]